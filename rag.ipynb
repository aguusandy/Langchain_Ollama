{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  RAG pdf implementation using langchain and ollama\n",
    "# https://python.langchain.com/docs/tutorials/rag/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model\n",
    "model = OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template\n",
    "template = \"\"\"\n",
    "You are an assistant that answers questions based on the provided context. The context is about files and documents.\n",
    "You should answer based in the context and you don't try to invent false information. If you can't answer the question, you retrive a response saying that you don't have the information to answer that.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't see any context provided. Can you please provide some information or clarify what kind of products you're referring to (e.g., electronics, beauty products, clothing, etc.)? I'll do my best to help!\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\"context\":[], \"question\": \"What is the best product?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ======================= Embedding ============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf files\n",
    "pdf_files = [\n",
    "    \"Andino_Agustin_Propuesta_PFC_2024.pdf\",\n",
    "    \"Informe_PFC_Andino_Agustin.pdf\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_location = \"./chrome_langchain_db\"\n",
    "add_documents = not os.path.exists(db_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Andino_Agustin_Propuesta_PFC_2024.pdf: 33 pages\n",
      "Loaded Informe_PFC_Andino_Agustin.pdf: 193 pages\n",
      "Total pages of documents loaded: 226\n"
     ]
    }
   ],
   "source": [
    "# load the files\n",
    "if add_documents:\n",
    "    documents = []\n",
    "    ids = []\n",
    "    for i, pdf_file in enumerate(pdf_files):\n",
    "        if os.path.exists(pdf_file):\n",
    "            loader = PyPDFLoader(pdf_file)\n",
    "            documents.extend(loader.load())\n",
    "            ids.append(i)\n",
    "            print(f\"Loaded {pdf_file}: {len(loader.load())} pages\")\n",
    "        else:\n",
    "            print(f\"File not found: {pdf_file}\")\n",
    "\n",
    "    print(f\"Total pages of documents loaded: {len(documents)}\")\n",
    "else:\n",
    "    print(\"Documents already loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text chunks created: 492\n"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.split_documents(documents)\n",
    "print(f\"Total text chunks created: {len(texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "UNIVERSIDADNACIONALDELLITORALFacultaddeIngenieríayCienciasHídricas\n",
      "PROPUESTADEPROYECTOFINALDECARRERAINGENIERÍAINFORMÁTICA\n",
      "Desarrollodemódulodeguardiaambulatoriacontriajeautomatizadomedianteinteligenciaartificial enel sistemawebSaDER.\n",
      "Alumno: Andino,DanielAgustin\n",
      "Director: MaríaAgustinaCarignan\n",
      "Co-Director:\n",
      "Asesortemático:\n",
      "SantaFe,Agostode2024\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Índice\n",
      "Resúmen 3PalabrasClaves 3Justificación 3Objetivo 6Alcance 7Metodología 8Plandetareas 13Cronogramadeactividades 17Puntosdeseguimiento 19Riesgos 20Recursos 24Presupuesto 25Plandecomunicaciones 28Bibliografía 30Referencias 31\n",
      "2\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Resumen\n"
     ]
    }
   ],
   "source": [
    "# Display first few chunks\n",
    "for i, text in enumerate(texts[:3]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(text.page_content[:500] + \"...\" if len(text.page_content) > 500 else text.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# Store the chunks\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"pdf_seeker\",\n",
    "    persist_directory=db_location,\n",
    "    embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_documents:\n",
    "    vector_store.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    question = input(\"Enter your question (q to quit): \")\n",
    "    if question.lower() == \"q\":\n",
    "        break\n",
    "    search = retriever.invoke(question)\n",
    "    result = chain.invoke({\"query\": search})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Name of the final project, the university or the educational institution and the name of the alumn who did it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final project is called \"Desarrollo de módulo de guardia ambulatoria con triaje automatizado mediante inteligencia artificial en el sistema web SaDER\".\n",
      "\n",
      "The university or educational institution where the student carried out the project is: UNIVERSIDAD NACIONAL DEL LITORAL.\n",
      "\n",
      "The name of the alumn who did the project is: ANDINO DANIEL AGUSTÍN.\n"
     ]
    }
   ],
   "source": [
    "search = retriever.invoke(question)\n",
    "\n",
    "# context of the documents\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in search])\n",
    "\n",
    "# prompt with the context and question\n",
    "prompt_input = f\"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
    "\n",
    "result = chain.invoke({\"context\": context, \"question\": question})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_unet",
   "language": "python",
   "name": "venv_unet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
